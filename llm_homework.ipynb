{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx9rDkNFVsP0"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "We did not do much classification in class although it is relevant in many industrial settings, for example:\n",
        "- spam detection\n",
        "- sentiment analysis\n",
        "- hate speech detection\n",
        "\n",
        "There are also several theoretical NLP problems that are framed as classification, such as Natural Language Inference.\n",
        "\n",
        "Because it is very basic, it gives you freedom to use any NLP method:\n",
        "- bag of words (not really seen in class)\n",
        "- word embeddings\n",
        "- LSTM/RNN\n",
        "- fine-tuned Transformer Encoder (e.g. BERT)...\n",
        "- ...with full fine-tuning or parameter efficient fine-tuning (e.g. LoRA)\n",
        "- prompted LLM (e.g. Llama)...\n",
        "- ...with standard prompting or chain of thought...\n",
        "- ...with or without In-Context Learning examples\n",
        "\n",
        "For this homework, we will study the detection of automatically generated text (more specifically, automatically generated research papers), based on the work of [Liyanage et al. 2022 \"A Benchmark Corpus for the Detection of Automatically Generated Text in Academic Publications\"](https://aclanthology.org/2022.lrec-1.501)\n",
        "\n",
        "> Automatic text generation based on neural language models has achieved performance levels that make the generated text almost indistinguishable from those written by humans. Despite the value that text generation can have in various applications, it can also be employed for malicious tasks. The diffusion of such practices represent a threat to the quality of academic publishing. To address these problems, we propose in this paper two datasets comprised of artificially generated research content: a completely synthetic dataset and a partial text substitution dataset. In the first case, the content is completely generated by the GPT-2 model after a short prompt extracted from original papers. The partial or hybrid dataset is created by replacing several sentences of abstracts with sentences that are generated by the Arxiv-NLP model. We evaluate the quality of the datasets comparing the generated texts to aligned original texts using fluency metrics such as BLEU and ROUGE. The more natural the artificial texts seem, the more difficult they are to detect and the better is the benchmark. We also evaluate the difficulty of the task of distinguishing original from generated text by using state-of-the-art classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebec84ad-2e31-4cc2-8bb5-63c07c3e0006"
      },
      "source": [
        "# Installation and imports\n",
        "\n",
        "Hit `Ctrl+S` to save a copy of the Colab notebook to your drive\n",
        "\n",
        "Run on Google Colab GPU:\n",
        "- Connect\n",
        "- Modify execution\n",
        "- GPU\n",
        "\n",
        "![image.png](https://paullerner.github.io/aivancity_nlp/_static/colab_gpu.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ8dHbLzfgSq",
        "outputId": "3e10412e-7e65-4ca2-d057-7b5157c42ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 25 16:23:41 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwN_Nn4VsP3"
      },
      "source": [
        "\n",
        "T4 GPU (on Google Colab) offers 15GB of memory. This should be enough to run inference and fine-tune LLMs of a few billion parameters (or less, obviously)\n",
        "\n",
        "Note, in `float32`, 1 parameter = 4 bytes so a LLM of 1B parameters holds 4GB of RAM.\n",
        "But for full fine-tuning, you will need to store gradient activations (without gradient checkpointing) and optimizer states (with optimizers like Adam).\n",
        "\n",
        "Turn to quantization for cheap inference of larger models or to Parameter Efficient Fine-Tuning for full-fine tuning of LLMs of a few billion parameters.\n",
        "\n",
        "Much simpler solution: stick to smaller models of hundred of millions of parameters (e.g. BERT, GPT-2, T5).\n",
        "You're not here to beat the state of the art but to learn NLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "4_g1yxfefP2r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "a-9phz_EfQ2d"
      },
      "outputs": [],
      "source": [
        "assert torch.cuda.is_available(), \"Connect to GPU and try again\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueztbJVrVsP5"
      },
      "source": [
        "# Data\n",
        "We will use the Hybrid subset of Vijini et al. in which some sentences of human-written abstracts where replaced by automatically-generated text. Experiments on the fully-generated subsets (or any other dataset) may provide bonus points (à faire)\n",
        "\n",
        "There are no train-test split provided in the paper but we keep 80% to train and 20% to test, following Vijini et al."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Remplacez 'nom_du_dossier' par le chemin du dossier que vous souhaitez supprimer\n",
        "dossier_a_supprimer = 'GeneratedTextDetection-main'\n",
        "\n",
        "try:# Supprimer le dossier et tout son contenu\n",
        "  shutil.rmtree(dossier_a_supprimer)\n",
        "  print(f\"Le dossier {dossier_a_supprimer} a été supprimé avec succès.\")\n",
        "except Exception:\n",
        "  print(f\"{dossier_a_supprimer} n\\'existe peut être pas\")\n",
        "finally:\n",
        "  print('téléchargemet du dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EhRwF2uz0OW",
        "outputId": "61b888c4-5d5a-4ade-82b3-cc715205182a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le dossier GeneratedTextDetection-main a été supprimé avec succès.\n",
            "téléchargemet du dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "scrolled": true,
        "id": "bQgqgPz3VsP6",
        "outputId": "a0a50511-2a4c-4671-d632-7094e936c0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-25 16:23:41--  https://github.com/vijini/GeneratedTextDetection/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/vijini/GeneratedTextDetection/zip/refs/heads/main [following]\n",
            "--2025-02-25 16:23:41--  https://codeload.github.com/vijini/GeneratedTextDetection/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.116.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.116.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip.1’\n",
            "\n",
            "main.zip.1              [ <=>                ] 800.25K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-02-25 16:23:41 (8.92 MB/s) - ‘main.zip.1’ saved [819461]\n",
            "\n",
            "Archive:  main.zip\n",
            "ab034465f857a93212a894fe598edb749345b6ff\n",
            "   creating: GeneratedTextDetection-main/\n",
            "  inflating: GeneratedTextDetection-main/BLEU_sentence.py  \n",
            "   creating: GeneratedTextDetection-main/Dataset/\n",
            "   creating: GeneratedTextDetection-main/Dataset/FullyGenerated/\n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.09779_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.09779_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10319_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10319_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10329_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10329_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10340_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10340_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10478_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10478_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10575_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10575_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10577_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10577_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10778_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10778_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10817_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10817_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11115_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11115_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11205_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11205_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11207_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11207_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11589_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11589_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11879_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11879_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11984_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11984_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12010_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12010_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12341_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12341_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12383_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12383_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12501_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12501_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12552_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12552_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12645_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12645_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12765_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12765_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13229_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13229_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13317_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13317_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13472_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13472_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13658_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13658_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13900_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13900_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.14532_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.14532_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15023_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15023_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15130_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15130_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15317_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15317_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15534_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15534_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15705_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15705_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15707_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15707_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15724_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15724_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15725_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15725_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15799_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15799_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15802_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15802_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00035_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00035_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00086_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00086_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00180_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00180_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00310_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00310_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00514_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00514_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00526_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00526_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00554_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00554_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00572_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00572_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00607_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00607_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00667_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00667_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00808_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00808_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00867_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00867_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01023_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01023_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01231_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01231_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01243_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01243_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01322_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01322_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01340_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01340_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01515_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01515_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01676_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01676_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01706_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01706_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02041_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02041_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02110_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02110_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02188_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02188_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02259_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02259_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02326_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02326_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02362_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02362_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02574_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02574_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02643_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02643_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02687_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02687_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02760_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02760_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02844_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02844_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03294_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03294_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03320_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03320_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03612_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03612_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03715_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03715_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03800_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03800_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03837_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03837_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03913_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03913_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03945_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03945_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04130_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04130_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04416_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04416_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04507_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04507_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04574_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04574_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05204_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05204_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05241_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05241_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05754_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05754_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06012_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06012_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06181_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06181_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06230_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06230_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06464_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06464_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06580_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06580_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06644_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06644_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07267_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07267_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07408_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07408_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07525_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07525_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07611_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07611_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07699_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07699_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07793_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07793_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15093_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15093_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15436_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15436_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15473_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15473_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2112.00405_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2112.00405_original.txt  \n",
            " extracting: GeneratedTextDetection-main/Dataset/FullyGenerated/data  \n",
            "   creating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/\n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09381_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09381_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09388_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09388_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09412_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09412_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09478_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09478_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09739_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09739_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09794_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09794_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09851_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09851_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09884_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09884_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09939_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09939_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10044_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10044_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10056_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10056_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10280_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10280_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10291_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10291_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10297_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10297_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10309_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10309_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10452_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10452_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10476_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10476_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10488_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10488_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10501_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10501_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10518_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10518_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10522_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10522_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10545_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10545_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10595_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10595_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10622_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10622_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10625_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10625_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10627_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10627_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10734_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10734_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10772_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10772_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10831_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10831_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10832_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10832_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10847_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10847_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10896_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10896_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10897_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10897_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10898_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10898_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10970_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10970_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11032_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11032_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11090_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11090_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11107_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11107_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11129_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11129_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11138_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11138_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11146_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11146_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11153_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11153_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11207_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11207_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11212_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11212_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11218_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11218_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11223_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11223_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11250_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11250_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11276_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11276_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11293_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11293_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11295_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11295_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11335_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11335_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11358_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11358_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11402_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11402_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11510_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11510_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11523_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11523_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11525_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11525_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11588_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11588_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11646_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11646_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11647_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11647_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11710_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11710_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11720_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11720_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11755_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11755_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11771_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11771_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11773_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11773_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11856_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11856_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11863_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11863_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11869_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11869_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11964_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11964_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11982_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11982_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12024_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12024_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12055_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12055_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12144_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12144_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12170_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12170_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12197_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12197_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12202_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12202_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12210_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12210_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12454_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12454_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12490_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12490_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12498_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12498_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12560_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12560_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12602_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12602_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12606_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12606_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12679_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12679_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12906_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12906_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12978_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12978_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12986_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12986_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13027_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13027_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13069_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13069_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13122_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13122_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13142_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13142_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13144_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13144_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13145_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13145_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13188_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13188_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13295_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13295_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13326_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13326_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13447_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13447_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13463_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13463_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13550_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13550_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13585_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13585_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13654_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13654_originalAbstract.txt  \n",
            " extracting: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/data  \n",
            "  inflating: GeneratedTextDetection-main/README.md  \n",
            "  inflating: GeneratedTextDetection-main/n-gram_BLEU.py  \n",
            "  inflating: GeneratedTextDetection-main/rouge.py  \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/vijini/GeneratedTextDetection/archive/refs/heads/main.zip\n",
        "!unzip main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "N2CEFL-PVsP6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "UDIRAm1AVsP7"
      },
      "outputs": [],
      "source": [
        "root = Path(\"GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "cRAWm2mrVsP7"
      },
      "outputs": [],
      "source": [
        "train_texts, train_labels, test_texts, test_labels = [], [], [], []\n",
        "for path in root.glob(\"*.txt\"):\n",
        "    with open(path, 'rt') as file:\n",
        "        text = file.read()\n",
        "        text = text.lstrip('\\ufeff')\n",
        "    label = int(path.name.endswith(\"generatedAbstract.txt\"))\n",
        "    doc_id = int(path.name.split(\"_\")[0].split(\".\")[-1])\n",
        "    if doc_id < 10522:\n",
        "        test_texts.append(text)\n",
        "        test_labels.append(label)\n",
        "    else:\n",
        "        train_texts.append(text)\n",
        "        train_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "4QVUO6vAVsP8",
        "outputId": "63f855ee-6d01-4ec8-9f53-10f817cb7f27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 160, 40, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "QwMK9c6iVsP8",
        "outputId": "5820f82e-4f81-4e00-ba8b-33a85e5d5777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Machine learning in medical imaging during clinical routine is impaired by changes in scan- ner protocols, hardware, or policies resulting in a heterogeneous set of acquisition settings. When training a deep learning model on an initial static training set, model performance and reliability suffer from changes of acquisition characteristics as data and targets may become inconsistent. Continual learning can help to adapt models to the changing environ- ment by training on a continuous data stream. However, continual manual expert labelling of medical imaging requires substantial effort. Thus, ways to use labelling resources ef- ficiently on a well chosen sub-set of new examples is necessary to render this strategy feasible. Here, we propose an integrated toolkit for automatic annotation of medical imaging , based on a deep embeddings framework for biomedical data, and present a method to automatically infer such annotation results using the full medical image corpus. The approach automatically recognizes shifts in image acquisition characteristics - new domains -, selects optimal examples for labelling and adapts training accordingly. Labelling is subject to a limited budget, resembling typ- ical real world scenarios. To demonstrate generalizability, we evaluate the effectiveness of our method on three tasks: cardiac segmentation, lung nodule detection and brain age estimation. Results show that the proposed approach outperforms other active learning methods, while effectively counteracting catastrophic forgetting.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "train_texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "luLbPRciVsP8",
        "outputId": "ad5fba9b-24d2-4ec3-90ea-3efbac2e17a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "wxv54Za-VsP9",
        "outputId": "f58d3bc6-ff89-47dc-9895-0501db95a2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Public policies that supply public goods, especially those involve collaboration by limiting individual liberty, always give rise to controversies over governance legitimacy. Multi-Agent Reinforcement Learning (MARL) methods are appropriate for supporting the legitimacy of the public policies that supply public goods at the cost of individual interests. Among these policies, the inter-regional collaborative pandemic control is a prominent example, which has become much more important for an increasingly inter-connected world facing a global pandemic like COVID-19. Different patterns of collaborative strategies have been observed among different systems of regions, yet it lacks an analytical process to reason for the legitimacy of those strategies. In this paper, we use the inter-regional collaboration for pandemic control as an example to demonstrate the necessity of MARL in reasoning, and thereby legitimizing policies enforcing such inter-regional collaboration. Exper- imental results in an exemplary environment show that our MARL approach is able to demonstrate the effectiveness and necessity of restrictions on individual liberty for collaborative supply of public goods. Different optimal policies are learned by our MARL agents under different collaboration levels, which change in an interpretable pattern of collaboration that helps to balance the losses suf- fered by regions of different types, and consequently promotes the overall welfare. Meanwhile, policies learned with higher collaboration levels yield higher global rewards, which illustrates the benefit of, and thus provides a novel justification for the legitimacy of, promoting inter-regional collaboration. Therefore, our method shows the capability of MARL in computationally modeling and supporting the theory of calculus of consent, developed by Nobel Prize winner J. M. Buchanan.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "train_texts[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "cJpoiYt5VsP9",
        "outputId": "1ca870f0-2ccd-4b81-b67b-2578ff3f2668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "train_labels[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlWApsrJVsP9"
      },
      "source": [
        "# Good luck!\n",
        "\n",
        "It's now up to you to solve the problem. You are free to choose any NLP method (cf. the list I gave above)\n",
        "but you should motivate your choice.\n",
        "You can also compare several methods to get bonus points. (compare 3 méthode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR3VXwlWVsP9"
      },
      "source": [
        "# Submission instructions\n",
        "\n",
        "\n",
        "**Deadline: Thursday 27th of February 23:59 (Paris CEST)** (strict deadline, 5 points malus per day late, so 4 days late means 0/20)\n",
        "\n",
        "This is a **group work** of **3 members**.\n",
        "\n",
        "You will have to submit your **code** and a **report** which will be graded (instructions below) by email to lerner@isir.upmc.fr.\n",
        "\n",
        "The homework (continuous assessment) will account for 50% of your final grade.\n",
        "\n",
        "## Report\n",
        "\n",
        "The report should be **a single .pdf file of max. 4 pages** (concision is key).\n",
        "Please name the pdf with the name of your group as written in the spreadsheet https://docs.google.com/spreadsheets/d/1UbApMhPC_wof-GoByjkV7kgD5YMbjcFFPqPUCB0YRtQ/edit?usp=sharing for example `ABC.pdf`.\n",
        "\n",
        "It should follow the following structure:\n",
        "\n",
        "### Introduction\n",
        "A few sentences placing the work in context. Limit it to a few paragraphs at most; since your report is based on Vijini et al., you don’t have to motivate that work. However, it should be clear enough what Vijini et al. is\n",
        "about and what its contributions are.\n",
        "\n",
        "### Methodology\n",
        "\n",
        "Describe the methods you are using to tackle the problem and motivate it: why this method and not another?  \n",
        "What are its advantages and inconvenients?  \n",
        "What experiment are you running to measure the efficiency or effectiveness of your method to tackle the problem?\n",
        "\n",
        "#### Model Descriptions\n",
        "Describe the models you used, including the architecture, learning objective and the number of parameters.\n",
        "\n",
        "#### Datasets\n",
        "Describe the datasets you used and how you obtained them.\n",
        "\n",
        "#### Hyperparameters\n",
        "Describe how you set the hyperparameters and what was the source for their value (e.g., paper, code, or your guess).\n",
        "\n",
        "#### Implementation\n",
        "Describe whether you use existing code or write your own code.\n",
        "\n",
        "#### Experimental Setup\n",
        "Explain how you ran your experiments, e.g. the CPU/GPU resources.\n",
        "\n",
        "### Results\n",
        "Start with a high-level overview of your results. Keep this\n",
        "section as factual and precise as possible.\n",
        "Logically\n",
        "group related results into sections.\n",
        "\n",
        "Remember to add plots and diagrams to illustrate your methods or results if necessary.\n",
        "\n",
        "\n",
        "\n",
        "### Discussion\n",
        "\n",
        "Describe which parts of your project were difficult or took much more time than you expected.\n",
        "\n",
        "\n",
        "### Contributions\n",
        "\n",
        "You should state the contributions of each member of the group.\n",
        "\n",
        "\n",
        "\n",
        "## Code\n",
        "\n",
        "You can submit your code either as:\n",
        "\n",
        "- single .zip file with your entire source code (e.g. several .py files)\n",
        "- link to a GitHub/GitLab repository (in this case, **include the link in your .pdf report**)\n",
        "- link to a Google Colab Notebook (your code may be quite simple so it may fit in a single notebook;\n",
        "  likewise, in this case, **include the link in your .pdf report**)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's start"
      ],
      "metadata": {
        "id": "gjgUSHD_y4cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#distribution"
      ],
      "metadata": {
        "id": "1PBFx2551Y3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Afficher la distribution des classes dans les ensembles d'entraînement et de test\n",
        "train_distribution = Counter(train_labels)\n",
        "test_distribution = Counter(test_labels)\n",
        "\n",
        "print(\"Data distribution in training set :\", train_distribution)\n",
        "print(\"Data distribution in test set :\", test_distribution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B1kC9TB1b5m",
        "outputId": "24c59655-b031-4d44-a191-a5a5a846484d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data distribution in training set : Counter({1: 80, 0: 80})\n",
            "Data distribution in test set : Counter({1: 20, 0: 20})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## conclusion: perfectly balanced dataset"
      ],
      "metadata": {
        "id": "c1sfgUVu2YEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "jDvJyKlWy9ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "#nltk local download\n",
        "nltk_data_path = '/content/nltk_data'\n",
        "os.makedirs(nltk_data_path, exist_ok=True)\n",
        "nltk.data.path.append(nltk_data_path)\n",
        "nltk.download('punkt_tab', download_dir=nltk_data_path)\n",
        "nltk.download('stopwords', download_dir=nltk_data_path)\n",
        "print(\"Chemins de recherche de NLTK :\", nltk.data.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LnDzATpy8Lr",
        "outputId": "aba24766-a69e-4d05-d0ca-10855b150b8b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chemins de recherche de NLTK : ['/root/nltk_data', '/usr/nltk_data', '/usr/share/nltk_data', '/usr/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/content/nltk_data', '/content/nltk_data', '/content/nltk_data', '/content/nltk_data']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "OYzGGfPW6ZMo"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Mettre en minuscules\n",
        "    text = text.lower()\n",
        "\n",
        "    # Supprimer la ponctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Tokeniser le texte\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Supprimer les stopwords\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "d-HgJmL33RWs"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_texts = [preprocess_text(text) for text in train_texts]\n",
        "print(\"Tokens prétraités :\", tokenized_train_texts[0][:10])"
      ],
      "metadata": {
        "id": "DFZxHUNC4sfm",
        "outputId": "2e3a545f-bb18-4c91-8d99-77fd0737251f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens prétraités : ['machine', 'learning', 'medical', 'imaging', 'clinical', 'routine', 'impaired', 'changes', 'scan', 'ner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features extraction"
      ],
      "metadata": {
        "id": "ji0wvJRq4hKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrice"
      ],
      "metadata": {
        "id": "DWtpLy5H8iUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Instanciation du vectorizer\n",
        "vectorizer_bow = CountVectorizer()\n",
        "\n",
        "# Transformation des textes d'entraînement et de test en matrices de comptage\n",
        "X_train_bow = vectorizer_bow.fit_transform(train_texts)\n",
        "X_test_bow = vectorizer_bow.transform(test_texts)\n",
        "\n",
        "print(\"Taille de la matrice d'entraînement (bag-of-words) :\", X_train_bow.shape)\n"
      ],
      "metadata": {
        "id": "r0vYGiih4gsl",
        "outputId": "3190624f-9368-431b-8a94-b6b4e8527cb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille de la matrice d'entraînement (bag-of-words) : (160, 3180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instanciation du vectorizer TF-IDF\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "\n",
        "# Transformation des textes d'entraînement et de test en matrices TF-IDF\n",
        "X_train_tfidf = vectorizer_tfidf.fit_transform(train_texts)\n",
        "X_test_tfidf = vectorizer_tfidf.transform(test_texts)\n",
        "\n",
        "print(\"Taille de la matrice d'entraînement (TF-IDF) :\", X_train_tfidf.shape)\n"
      ],
      "metadata": {
        "id": "Oj8wX4kG8xVj",
        "outputId": "4020da41-129f-4795-a4e5-a7df7c6abd43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille de la matrice d'entraînement (TF-IDF) : (160, 3180)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lazypredict"
      ],
      "metadata": {
        "id": "ziI3YqJmBpc1",
        "outputId": "ddff63b4-f2e8-4c63-e109-15d40b6c94c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.13-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from lazypredict) (8.1.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lazypredict) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from lazypredict) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lazypredict) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from lazypredict) (1.4.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from lazypredict) (4.5.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from lazypredict) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm->lazypredict) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm->lazypredict) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->lazypredict) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->lazypredict) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lazypredict) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->lazypredict) (2.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.17.0)\n",
            "Downloading lazypredict-0.2.13-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from lazypredict.Supervised import LazyClassifier"
      ],
      "metadata": {
        "id": "8DGQizyXBtK6",
        "outputId": "28b694bb-479c-4c80-8e48-78d3dc185204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lazy predict to compare model (TFidf)"
      ],
      "metadata": {
        "id": "XQhzXVCA_Ra_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train_tfidf.toarray(), X_test_tfidf.toarray(), train_labels, test_labels)\n",
        "models\n"
      ],
      "metadata": {
        "id": "OoYFWKXPCKn7",
        "outputId": "7b9c90cc-0c8a-43f7-81b3-eaa3abc836d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:11<00:00,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 80, number of negative: 80\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2553\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 138\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "XGBClassifier                      0.68               0.68     0.68      0.67   \n",
              "LGBMClassifier                     0.62               0.62     0.62      0.62   \n",
              "BernoulliNB                        0.62               0.62     0.62      0.62   \n",
              "SGDClassifier                      0.60               0.60     0.60      0.60   \n",
              "BaggingClassifier                  0.60               0.60     0.60      0.60   \n",
              "NearestCentroid                    0.57               0.57     0.57      0.57   \n",
              "RandomForestClassifier             0.57               0.57     0.57      0.55   \n",
              "Perceptron                         0.57               0.57     0.58      0.57   \n",
              "SVC                                0.55               0.55     0.55      0.55   \n",
              "QuadraticDiscriminantAnalysis      0.55               0.55     0.55      0.55   \n",
              "LinearDiscriminantAnalysis         0.55               0.55     0.55      0.55   \n",
              "RidgeClassifierCV                  0.53               0.53     0.53      0.52   \n",
              "RidgeClassifier                    0.53               0.53     0.53      0.52   \n",
              "PassiveAggressiveClassifier        0.53               0.53     0.53      0.52   \n",
              "NuSVC                              0.53               0.53     0.53      0.49   \n",
              "AdaBoostClassifier                 0.53               0.53     0.53      0.52   \n",
              "LogisticRegression                 0.53               0.53     0.53      0.52   \n",
              "ExtraTreesClassifier               0.53               0.53     0.53      0.50   \n",
              "LinearSVC                          0.53               0.53     0.53      0.52   \n",
              "LabelSpreading                     0.50               0.50     0.50      0.33   \n",
              "LabelPropagation                   0.50               0.50     0.50      0.33   \n",
              "KNeighborsClassifier               0.50               0.50     0.50      0.37   \n",
              "GaussianNB                         0.50               0.50     0.50      0.49   \n",
              "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
              "DecisionTreeClassifier             0.50               0.50     0.50      0.50   \n",
              "ExtraTreeClassifier                0.47               0.48     0.48      0.47   \n",
              "CalibratedClassifierCV             0.42               0.43     0.42      0.42   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "XGBClassifier                        0.43  \n",
              "LGBMClassifier                       0.12  \n",
              "BernoulliNB                          0.19  \n",
              "SGDClassifier                        0.11  \n",
              "BaggingClassifier                    0.83  \n",
              "NearestCentroid                      0.10  \n",
              "RandomForestClassifier               0.29  \n",
              "Perceptron                           0.11  \n",
              "SVC                                  0.15  \n",
              "QuadraticDiscriminantAnalysis        0.19  \n",
              "LinearDiscriminantAnalysis           0.23  \n",
              "RidgeClassifierCV                    0.18  \n",
              "RidgeClassifier                      0.23  \n",
              "PassiveAggressiveClassifier          0.12  \n",
              "NuSVC                                0.11  \n",
              "AdaBoostClassifier                   0.69  \n",
              "LogisticRegression                   0.13  \n",
              "ExtraTreesClassifier                 0.27  \n",
              "LinearSVC                            0.96  \n",
              "LabelSpreading                       0.10  \n",
              "LabelPropagation                     0.08  \n",
              "KNeighborsClassifier                 0.07  \n",
              "GaussianNB                           0.06  \n",
              "DummyClassifier                      0.06  \n",
              "DecisionTreeClassifier               0.11  \n",
              "ExtraTreeClassifier                  0.06  \n",
              "CalibratedClassifierCV               5.18  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5a585e4-5e70-42b9-9d7b-850bf904cc7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.68</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVC</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelSpreading</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelPropagation</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.47</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>5.18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5a585e4-5e70-42b9-9d7b-850bf904cc7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5a585e4-5e70-42b9-9d7b-850bf904cc7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5a585e4-5e70-42b9-9d7b-850bf904cc7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33a3ae52-9099-4e78-99e7-86b6a47cb9a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33a3ae52-9099-4e78-99e7-86b6a47cb9a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33a3ae52-9099-4e78-99e7-86b6a47cb9a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8489d94b-5bb2-4816-baf0-c0523c600917\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('models')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8489d94b-5bb2-4816-baf0-c0523c600917 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('models');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "models",
              "summary": "{\n  \"name\": \"models\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"SVC\",\n          \"PassiveAggressiveClassifier\",\n          \"QuadraticDiscriminantAnalysis\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05287328290908412,\n        \"min\": 0.425,\n        \"max\": 0.675,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.475,\n          0.625,\n          0.525\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balanced Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.052873282909084114,\n        \"min\": 0.42500000000000004,\n        \"max\": 0.675,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.47500000000000003,\n          0.625,\n          0.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05287328290908412,\n        \"min\": 0.42499999999999993,\n        \"max\": 0.675,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.55,\n          0.675,\n          0.47500000000000003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08880721177727799,\n        \"min\": 0.3333333333333333,\n        \"max\": 0.6731615336266499,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.6731615336266499,\n          0.5725958516656191,\n          0.4861392832995267\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time Taken\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9801311337252094,\n        \"min\": 0.05621910095214844,\n        \"max\": 5.175907850265503,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.14696073532104492,\n          0.12488746643066406,\n          0.19298458099365234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lazy predict to compare model (bow)"
      ],
      "metadata": {
        "id": "A12miNNJC9fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "models, predictions = clf.fit(X_train_bow.toarray(), X_test_bow.toarray(), train_labels, test_labels)\n",
        "models"
      ],
      "metadata": {
        "id": "Waaa_MCyC_zk",
        "outputId": "8e22be55-b8fb-4889-bf66-bd7ce8b5eef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:08<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 80, number of negative: 80\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 160, number of used features: 138\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
              "Model                                                                           \n",
              "ExtraTreesClassifier               0.65               0.65     0.65      0.64   \n",
              "RandomForestClassifier             0.65               0.65     0.65      0.65   \n",
              "BernoulliNB                        0.62               0.62     0.62      0.62   \n",
              "LGBMClassifier                     0.60               0.60     0.60      0.60   \n",
              "XGBClassifier                      0.60               0.60     0.60      0.60   \n",
              "ExtraTreeClassifier                0.60               0.60     0.60      0.60   \n",
              "QuadraticDiscriminantAnalysis      0.57               0.57     0.57      0.57   \n",
              "RidgeClassifierCV                  0.57               0.57     0.57      0.57   \n",
              "RidgeClassifier                    0.57               0.57     0.57      0.57   \n",
              "LinearSVC                          0.57               0.57     0.57      0.57   \n",
              "Perceptron                         0.55               0.55     0.55      0.55   \n",
              "LogisticRegression                 0.55               0.55     0.55      0.55   \n",
              "NearestCentroid                    0.55               0.55     0.55      0.55   \n",
              "PassiveAggressiveClassifier        0.55               0.55     0.55      0.55   \n",
              "DecisionTreeClassifier             0.55               0.55     0.55      0.55   \n",
              "LinearDiscriminantAnalysis         0.53               0.53     0.53      0.52   \n",
              "BaggingClassifier                  0.53               0.53     0.53      0.50   \n",
              "SVC                                0.53               0.53     0.53      0.50   \n",
              "SGDClassifier                      0.53               0.53     0.53      0.52   \n",
              "GaussianNB                         0.53               0.53     0.53      0.52   \n",
              "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
              "LabelPropagation                   0.50               0.50     0.50      0.33   \n",
              "KNeighborsClassifier               0.50               0.50     0.50      0.33   \n",
              "LabelSpreading                     0.50               0.50     0.50      0.33   \n",
              "NuSVC                              0.50               0.50     0.50      0.50   \n",
              "AdaBoostClassifier                 0.50               0.50     0.50      0.49   \n",
              "CalibratedClassifierCV             0.42               0.43     0.43      0.42   \n",
              "\n",
              "                               Time Taken  \n",
              "Model                                      \n",
              "ExtraTreesClassifier                 0.29  \n",
              "RandomForestClassifier               0.43  \n",
              "BernoulliNB                          0.11  \n",
              "LGBMClassifier                       0.18  \n",
              "XGBClassifier                        0.58  \n",
              "ExtraTreeClassifier                  0.06  \n",
              "QuadraticDiscriminantAnalysis        0.26  \n",
              "RidgeClassifierCV                    0.22  \n",
              "RidgeClassifier                      0.14  \n",
              "LinearSVC                            0.87  \n",
              "Perceptron                           0.12  \n",
              "LogisticRegression                   0.14  \n",
              "NearestCentroid                      0.10  \n",
              "PassiveAggressiveClassifier          0.12  \n",
              "DecisionTreeClassifier               0.10  \n",
              "LinearDiscriminantAnalysis           0.27  \n",
              "BaggingClassifier                    0.36  \n",
              "SVC                                  0.19  \n",
              "SGDClassifier                        0.16  \n",
              "GaussianNB                           0.06  \n",
              "DummyClassifier                      0.05  \n",
              "LabelPropagation                     0.08  \n",
              "KNeighborsClassifier                 0.06  \n",
              "LabelSpreading                       0.10  \n",
              "NuSVC                                0.10  \n",
              "AdaBoostClassifier                   0.53  \n",
              "CalibratedClassifierCV               2.33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a895a8da-038a-47dc-948f-dc61e082a536\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Time Taken</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ExtraTreesClassifier</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BernoulliNB</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LGBMClassifier</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBClassifier</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExtraTreeClassifier</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>QuadraticDiscriminantAnalysis</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifierCV</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RidgeClassifier</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Perceptron</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NearestCentroid</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassiveAggressiveClassifier</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearDiscriminantAnalysis</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BaggingClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelPropagation</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LabelSpreading</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NuSVC</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CalibratedClassifierCV</th>\n",
              "      <td>0.42</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.42</td>\n",
              "      <td>2.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a895a8da-038a-47dc-948f-dc61e082a536')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a895a8da-038a-47dc-948f-dc61e082a536 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a895a8da-038a-47dc-948f-dc61e082a536');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17b47f5e-706b-40a2-93d3-2f68cb4aa8bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17b47f5e-706b-40a2-93d3-2f68cb4aa8bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17b47f5e-706b-40a2-93d3-2f68cb4aa8bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_51761e19-931e-4865-a886-038e3f0c3320\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('models')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_51761e19-931e-4865-a886-038e3f0c3320 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('models');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "models",
              "summary": "{\n  \"name\": \"models\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"RidgeClassifier\",\n          \"PassiveAggressiveClassifier\",\n          \"LinearSVC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05164667382686826,\n        \"min\": 0.425,\n        \"max\": 0.65,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.625,\n          0.525,\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Balanced Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05164667382686825,\n        \"min\": 0.42500000000000004,\n        \"max\": 0.65,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.625,\n          0.525,\n          0.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05164667382686824,\n        \"min\": 0.42500000000000004,\n        \"max\": 0.65,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5,\n          0.65,\n          0.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09299517641577866,\n        \"min\": 0.3333333333333333,\n        \"max\": 0.65,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5223130106851037,\n          0.3333333333333333,\n          0.6354166666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time Taken\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4486441364254701,\n        \"min\": 0.05458521842956543,\n        \"max\": 2.326538324356079,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.14300107955932617,\n          0.12439441680908203,\n          0.8682565689086914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}