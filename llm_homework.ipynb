{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx9rDkNFVsP0"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "We did not do much classification in class although it is relevant in many industrial settings, for example:\n",
        "- spam detection\n",
        "- sentiment analysis\n",
        "- hate speech detection\n",
        "\n",
        "There are also several theoretical NLP problems that are framed as classification, such as Natural Language Inference.\n",
        "\n",
        "Because it is very basic, it gives you freedom to use any NLP method:\n",
        "- bag of words (not really seen in class)\n",
        "- word embeddings\n",
        "- LSTM/RNN\n",
        "- fine-tuned Transformer Encoder (e.g. BERT)...\n",
        "- ...with full fine-tuning or parameter efficient fine-tuning (e.g. LoRA)\n",
        "- prompted LLM (e.g. Llama)...\n",
        "- ...with standard prompting or chain of thought...\n",
        "- ...with or without In-Context Learning examples\n",
        "\n",
        "For this homework, we will study the detection of automatically generated text (more specifically, automatically generated research papers), based on the work of [Liyanage et al. 2022 \"A Benchmark Corpus for the Detection of Automatically Generated Text in Academic Publications\"](https://aclanthology.org/2022.lrec-1.501)\n",
        "\n",
        "> Automatic text generation based on neural language models has achieved performance levels that make the generated text almost indistinguishable from those written by humans. Despite the value that text generation can have in various applications, it can also be employed for malicious tasks. The diffusion of such practices represent a threat to the quality of academic publishing. To address these problems, we propose in this paper two datasets comprised of artificially generated research content: a completely synthetic dataset and a partial text substitution dataset. In the first case, the content is completely generated by the GPT-2 model after a short prompt extracted from original papers. The partial or hybrid dataset is created by replacing several sentences of abstracts with sentences that are generated by the Arxiv-NLP model. We evaluate the quality of the datasets comparing the generated texts to aligned original texts using fluency metrics such as BLEU and ROUGE. The more natural the artificial texts seem, the more difficult they are to detect and the better is the benchmark. We also evaluate the difficulty of the task of distinguishing original from generated text by using state-of-the-art classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebec84ad-2e31-4cc2-8bb5-63c07c3e0006"
      },
      "source": [
        "# Installation and imports\n",
        "\n",
        "Hit `Ctrl+S` to save a copy of the Colab notebook to your drive\n",
        "\n",
        "Run on Google Colab GPU:\n",
        "- Connect\n",
        "- Modify execution\n",
        "- GPU\n",
        "\n",
        "![image.png](https://paullerner.github.io/aivancity_nlp/_static/colab_gpu.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ8dHbLzfgSq",
        "outputId": "00d59a58-1784-4458-d1b3-e7a74eb94621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Sep 26 08:42:32 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwN_Nn4VsP3"
      },
      "source": [
        "\n",
        "T4 GPU (on Google Colab) offers 15GB of memory. This should be enough to run inference and fine-tune LLMs of a few billion parameters (or less, obviously)\n",
        "\n",
        "Note, in `float32`, 1 parameter = 4 bytes so a LLM of 1B parameters holds 4GB of RAM.\n",
        "But for full fine-tuning, you will need to store gradient activations (without gradient checkpointing) and optimizer states (with optimizers like Adam).\n",
        "\n",
        "Turn to quantization for cheap inference of larger models or to Parameter Efficient Fine-Tuning for full-fine tuning of LLMs of a few billion parameters.\n",
        "\n",
        "Much simpler solution: stick to smaller models of hundred of millions of parameters (e.g. BERT, GPT-2, T5).\n",
        "You're not here to beat the state of the art but to learn NLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_g1yxfefP2r"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-9phz_EfQ2d"
      },
      "outputs": [],
      "source": [
        "assert torch.cuda.is_available(), \"Connect to GPU and try again\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueztbJVrVsP5"
      },
      "source": [
        "# Data\n",
        "We will use the Hybrid subset of Vijini et al. in which some sentences of human-written abstracts where replaced by automatically-generated text. Experiments on the fully-generated subsets (or any other dataset) may provide bonus points (Ã  faire)\n",
        "\n",
        "There are no train-test split provided in the paper but we keep 80% to train and 20% to test, following Vijini et al."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bQgqgPz3VsP6",
        "outputId": "9ae74a8d-daf0-4807-9c6d-27e7d63fd695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-27 16:44:25--  https://github.com/vijini/GeneratedTextDetection/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/vijini/GeneratedTextDetection/zip/refs/heads/main [following]\n",
            "--2024-12-27 16:44:25--  https://codeload.github.com/vijini/GeneratedTextDetection/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.121.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.121.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: 'main.zip'\n",
            "\n",
            "main.zip                [ <=>                ] 800.25K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-12-27 16:44:26 (10.9 MB/s) - 'main.zip' saved [819461]\n",
            "\n",
            "Archive:  main.zip\n",
            "ab034465f857a93212a894fe598edb749345b6ff\n",
            "   creating: GeneratedTextDetection-main/\n",
            "  inflating: GeneratedTextDetection-main/BLEU_sentence.py  \n",
            "   creating: GeneratedTextDetection-main/Dataset/\n",
            "   creating: GeneratedTextDetection-main/Dataset/FullyGenerated/\n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.09779_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.09779_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10319_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10319_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10329_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10329_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10340_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10340_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10478_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10478_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10575_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10575_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10577_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10577_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10778_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10778_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10817_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10817_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11115_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11115_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11205_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11205_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11207_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11207_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11589_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11589_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11879_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11879_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11984_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11984_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12010_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12010_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12341_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12341_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12383_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12383_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12501_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12501_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12552_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12552_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12645_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12645_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12765_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12765_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13229_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13229_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13317_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13317_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13472_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13472_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13658_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13658_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13900_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13900_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.14532_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.14532_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15023_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15023_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15130_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15130_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15317_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15317_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15534_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15534_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15705_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15705_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15707_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15707_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15724_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15724_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15725_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15725_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15799_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15799_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15802_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15802_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00035_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00035_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00086_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00086_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00180_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00180_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00310_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00310_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00514_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00514_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00526_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00526_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00554_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00554_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00572_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00572_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00607_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00607_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00667_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00667_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00808_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00808_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00867_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00867_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01023_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01023_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01231_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01231_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01243_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01243_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01322_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01322_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01340_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01340_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01515_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01515_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01676_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01676_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01706_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01706_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02041_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02041_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02110_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02110_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02188_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02188_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02259_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02259_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02326_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02326_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02362_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02362_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02574_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02574_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02643_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02643_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02687_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02687_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02760_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02760_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02844_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02844_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03294_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03294_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03320_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03320_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03612_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03612_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03715_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03715_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03800_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03800_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03837_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03837_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03913_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03913_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03945_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03945_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04130_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04130_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04416_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04416_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04507_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04507_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04574_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04574_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05204_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05204_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05241_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05241_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05754_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05754_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06012_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06012_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06181_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06181_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06230_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06230_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06464_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06464_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06580_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06580_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06644_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06644_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07267_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07267_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07408_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07408_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07525_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07525_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07611_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07611_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07699_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07699_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07793_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07793_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15093_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15093_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15436_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15436_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15473_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15473_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2112.00405_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2112.00405_original.txt  \n",
            " extracting: GeneratedTextDetection-main/Dataset/FullyGenerated/data  \n",
            "   creating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/\n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09381_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09381_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09388_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09388_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09412_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09412_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09478_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09478_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09739_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09739_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09794_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09794_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09851_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09851_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09884_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09884_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09939_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09939_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10044_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10044_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10056_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10056_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10280_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10280_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10291_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10291_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10297_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10297_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10309_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10309_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10452_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10452_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10476_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10476_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10488_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10488_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10501_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10501_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10518_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10518_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10522_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10522_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10545_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10545_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10595_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10595_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10622_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10622_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10625_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10625_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10627_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10627_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10734_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10734_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10772_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10772_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10831_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10831_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10832_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10832_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10847_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10847_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10896_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10896_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10897_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10897_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10898_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10898_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10970_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10970_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11032_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11032_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11090_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11090_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11107_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11107_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11129_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11129_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11138_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11138_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11146_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11146_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11153_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11153_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11207_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11207_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11212_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11212_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11218_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11218_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11223_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11223_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11250_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11250_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11276_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11276_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11293_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11293_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11295_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11295_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11335_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11335_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11358_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11358_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11402_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11402_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11510_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11510_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11523_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11523_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11525_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11525_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11588_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11588_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11646_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11646_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11647_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11647_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11710_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11710_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11720_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11720_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11755_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11755_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11771_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11771_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11773_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11773_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11856_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11856_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11863_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11863_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11869_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11869_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11964_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11964_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11982_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11982_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12024_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12024_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12055_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12055_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12144_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12144_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12170_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12170_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12197_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12197_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12202_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12202_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12210_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12210_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12454_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12454_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12490_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12490_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12498_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12498_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12560_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12560_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12602_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12602_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12606_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12606_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12679_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12679_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12906_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12906_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12978_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12978_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12986_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12986_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13027_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13027_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13069_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13069_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13122_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13122_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13142_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13142_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13144_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13144_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13145_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13145_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13188_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13188_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13295_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13295_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13326_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13326_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13447_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13447_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13463_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13463_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13550_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13550_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13585_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13585_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13654_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13654_originalAbstract.txt  \n",
            " extracting: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/data  \n",
            "  inflating: GeneratedTextDetection-main/README.md  \n",
            "  inflating: GeneratedTextDetection-main/n-gram_BLEU.py  \n",
            "  inflating: GeneratedTextDetection-main/rouge.py  \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/vijini/GeneratedTextDetection/archive/refs/heads/main.zip\n",
        "!unzip main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2CEFL-PVsP6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDIRAm1AVsP7"
      },
      "outputs": [],
      "source": [
        "root = Path(\"GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRAWm2mrVsP7"
      },
      "outputs": [],
      "source": [
        "train_texts, train_labels, test_texts, test_labels = [], [], [], []\n",
        "for path in root.glob(\"*.txt\"):\n",
        "    with open(path, 'rt') as file:\n",
        "        text = file.read()\n",
        "    label = int(path.name.endswith(\"generatedAbstract.txt\"))\n",
        "    doc_id = int(path.name.split(\"_\")[0].split(\".\")[-1])\n",
        "    if doc_id < 10522:\n",
        "        test_texts.append(text)\n",
        "        test_labels.append(label)\n",
        "    else:\n",
        "        train_texts.append(text)\n",
        "        train_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QVUO6vAVsP8",
        "outputId": "086f3677-8f50-4671-9d2a-c0fcbe06697d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(160, 160, 40, 40)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwMK9c6iVsP8",
        "outputId": "fcd141a0-28fd-41de-a270-45e55976f820"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ufeffRemembering and forgetting mechanisms are two sides of the same coin in a human learning-memory system. Inspired by human brain memory mechanisms, modern machine learning systems have been working to endow machine with lifelong learning capability through better remembering while pushing the forgetting as the antagonist to overcome. Nevertheless, this idea might only see the half picture. Up until very recently, increasing researchers argue that a brain is born to forget, i.e., forgetting is a natural and active process for abstract, rich, and flexible representations. This paper presents  an exploration of neural machine learning models that use a memory model to learn and forget. The active forgetting mechanism (AFM) is introduced to a neural network via a \"plug-and-play\" forgetting layer (P&PF), consisting of groups of inhibitory neurons with Internal Regulation Strategy (IRS) to adjust the extinction rate of themselves via lateral inhibition mechanism and External Regulation Strategy (ERS) to adjust the extinction rate of excitatory neurons via inhibition mechanism. Experimental studies have shown that the P&PF offers surprising benefits: self-adaptive structure, strong generalization, long-term learning and memory, and robustness to data and parameter perturbation. This work sheds light on the importance of forgetting in the learning process and offers new perspectives to understand underlying mechanisms of neural networks.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luLbPRciVsP8",
        "outputId": "07c3409e-9d04-4ff0-f76f-38777bf47315"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxv54Za-VsP9",
        "outputId": "31762824-95b5-4721-c220-6b47f05ae1b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ufeffNormalising flows are flexible, parameterized distributions that can be used to approximate expectations from intractable distributions via importance sampling. However, current flow-based approaches are limited on challenging targets where they either suffer from mode seeking behaviour or high variance in the training loss, or rely on samples from the target distribution, which may not be available. To address these challenges, we combine flows with annealed importance sampling (AIS), while using the Î±-divergence as our objective, in a novel training procedure, FAB (Flow AIS Bootstrap). Thereby, the flow and AIS to improve each other in a bootstrapping manner. We demonstrate that FAB can be used to produce accurate approximations to complex target distributions, including Boltzmann distributions, in problems where previous flow-based methods fail.'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_texts[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJpoiYt5VsP9",
        "outputId": "6e350cde-c76d-41aa-a21d-9c99ceaef624"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlWApsrJVsP9"
      },
      "source": [
        "# Good luck!\n",
        "\n",
        "It's now up to you to solve the problem. You are free to choose any NLP method (cf. the list I gave above)\n",
        "but you should motivate your choice.\n",
        "You can also compare several methods to get bonus points. (compare 3 mÃ©thode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR3VXwlWVsP9"
      },
      "source": [
        "# Submission instructions\n",
        "\n",
        "\n",
        "**Deadline: Thursday 27th of February 23:59 (Paris CEST)** (strict deadline, 5 points malus per day late, so 4 days late means 0/20)\n",
        "\n",
        "This is a **group work** of **3 members**.\n",
        "\n",
        "You will have to submit your **code** and a **report** which will be graded (instructions below) by email to lerner@isir.upmc.fr.\n",
        "\n",
        "The homework (continuous assessment) will account for 50% of your final grade.\n",
        "\n",
        "## Report\n",
        "\n",
        "The report should be **a single .pdf file of max. 4 pages** (concision is key).\n",
        "Please name the pdf with the name of your group as written in the spreadsheet https://docs.google.com/spreadsheets/d/1UbApMhPC_wof-GoByjkV7kgD5YMbjcFFPqPUCB0YRtQ/edit?usp=sharing for example `ABC.pdf`.\n",
        "\n",
        "It should follow the following structure:\n",
        "\n",
        "### Introduction\n",
        "A few sentences placing the work in context. Limit it to a few paragraphs at most; since your report is based on Vijini et al., you donât have to motivate that work. However, it should be clear enough what Vijini et al. is\n",
        "about and what its contributions are.\n",
        "\n",
        "### Methodology\n",
        "\n",
        "Describe the methods you are using to tackle the problem and motivate it: why this method and not another?  \n",
        "What are its advantages and inconvenients?  \n",
        "What experiment are you running to measure the efficiency or effectiveness of your method to tackle the problem?\n",
        "\n",
        "#### Model Descriptions\n",
        "Describe the models you used, including the architecture, learning objective and the number of parameters.\n",
        "\n",
        "#### Datasets\n",
        "Describe the datasets you used and how you obtained them.\n",
        "\n",
        "#### Hyperparameters\n",
        "Describe how you set the hyperparameters and what was the source for their value (e.g., paper, code, or your guess).\n",
        "\n",
        "#### Implementation\n",
        "Describe whether you use existing code or write your own code.\n",
        "\n",
        "#### Experimental Setup\n",
        "Explain how you ran your experiments, e.g. the CPU/GPU resources.\n",
        "\n",
        "### Results\n",
        "Start with a high-level overview of your results. Keep this\n",
        "section as factual and precise as possible.\n",
        "Logically\n",
        "group related results into sections.\n",
        "\n",
        "Remember to add plots and diagrams to illustrate your methods or results if necessary.\n",
        "\n",
        "\n",
        "\n",
        "### Discussion\n",
        "\n",
        "Describe which parts of your project were difficult or took much more time than you expected.\n",
        "\n",
        "\n",
        "### Contributions\n",
        "\n",
        "You should state the contributions of each member of the group.\n",
        "\n",
        "\n",
        "\n",
        "## Code\n",
        "\n",
        "You can submit your code either as:\n",
        "\n",
        "- single .zip file with your entire source code (e.g. several .py files)\n",
        "- link to a GitHub/GitLab repository (in this case, **include the link in your .pdf report**)\n",
        "- link to a Google Colab Notebook (your code may be quite simple so it may fit in a single notebook;\n",
        "  likewise, in this case, **include the link in your .pdf report**)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}