{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx9rDkNFVsP0"
      },
      "source": [
        "# Text Classification\n",
        "\n",
        "We did not do much classification in class although it is relevant in many industrial settings, for example:\n",
        "- spam detection\n",
        "- sentiment analysis\n",
        "- hate speech detection\n",
        "\n",
        "There are also several theoretical NLP problems that are framed as classification, such as Natural Language Inference.\n",
        "\n",
        "Because it is very basic, it gives you freedom to use any NLP method:\n",
        "- bag of words (not really seen in class)\n",
        "- word embeddings\n",
        "- LSTM/RNN\n",
        "- fine-tuned Transformer Encoder (e.g. BERT)...\n",
        "- ...with full fine-tuning or parameter efficient fine-tuning (e.g. LoRA)\n",
        "- prompted LLM (e.g. Llama)...\n",
        "- ...with standard prompting or chain of thought...\n",
        "- ...with or without In-Context Learning examples\n",
        "\n",
        "For this homework, we will study the detection of automatically generated text (more specifically, automatically generated research papers), based on the work of [Liyanage et al. 2022 \"A Benchmark Corpus for the Detection of Automatically Generated Text in Academic Publications\"](https://aclanthology.org/2022.lrec-1.501)\n",
        "\n",
        "> Automatic text generation based on neural language models has achieved performance levels that make the generated text almost indistinguishable from those written by humans. Despite the value that text generation can have in various applications, it can also be employed for malicious tasks. The diffusion of such practices represent a threat to the quality of academic publishing. To address these problems, we propose in this paper two datasets comprised of artificially generated research content: a completely synthetic dataset and a partial text substitution dataset. In the first case, the content is completely generated by the GPT-2 model after a short prompt extracted from original papers. The partial or hybrid dataset is created by replacing several sentences of abstracts with sentences that are generated by the Arxiv-NLP model. We evaluate the quality of the datasets comparing the generated texts to aligned original texts using fluency metrics such as BLEU and ROUGE. The more natural the artificial texts seem, the more difficult they are to detect and the better is the benchmark. We also evaluate the difficulty of the task of distinguishing original from generated text by using state-of-the-art classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebec84ad-2e31-4cc2-8bb5-63c07c3e0006"
      },
      "source": [
        "# Installation and imports\n",
        "\n",
        "Hit `Ctrl+S` to save a copy of the Colab notebook to your drive\n",
        "\n",
        "Run on Google Colab GPU:\n",
        "- Connect\n",
        "- Modify execution\n",
        "- GPU\n",
        "\n",
        "![image.png](https://paullerner.github.io/aivancity_nlp/_static/colab_gpu.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ8dHbLzfgSq",
        "outputId": "dd12006f-7d6a-423d-9a63-50f416d636fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 25 15:55:22 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLwN_Nn4VsP3"
      },
      "source": [
        "\n",
        "T4 GPU (on Google Colab) offers 15GB of memory. This should be enough to run inference and fine-tune LLMs of a few billion parameters (or less, obviously)\n",
        "\n",
        "Note, in `float32`, 1 parameter = 4 bytes so a LLM of 1B parameters holds 4GB of RAM.\n",
        "But for full fine-tuning, you will need to store gradient activations (without gradient checkpointing) and optimizer states (with optimizers like Adam).\n",
        "\n",
        "Turn to quantization for cheap inference of larger models or to Parameter Efficient Fine-Tuning for full-fine tuning of LLMs of a few billion parameters.\n",
        "\n",
        "Much simpler solution: stick to smaller models of hundred of millions of parameters (e.g. BERT, GPT-2, T5).\n",
        "You're not here to beat the state of the art but to learn NLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4_g1yxfefP2r"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "a-9phz_EfQ2d"
      },
      "outputs": [],
      "source": [
        "assert torch.cuda.is_available(), \"Connect to GPU and try again\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueztbJVrVsP5"
      },
      "source": [
        "# Data\n",
        "We will use the Hybrid subset of Vijini et al. in which some sentences of human-written abstracts where replaced by automatically-generated text. Experiments on the fully-generated subsets (or any other dataset) may provide bonus points (à faire)\n",
        "\n",
        "There are no train-test split provided in the paper but we keep 80% to train and 20% to test, following Vijini et al."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Remplacez 'nom_du_dossier' par le chemin du dossier que vous souhaitez supprimer\n",
        "dossier_a_supprimer = 'GeneratedTextDetection-main'\n",
        "\n",
        "try:# Supprimer le dossier et tout son contenu\n",
        "  shutil.rmtree(dossier_a_supprimer)\n",
        "  print(f\"Le dossier {dossier_a_supprimer} a été supprimé avec succès.\")\n",
        "except Exception:\n",
        "  print(f\"{dossier_a_supprimer} n\\'existe peut être pas\")\n",
        "finally:\n",
        "  print('téléchargemet du dataset')"
      ],
      "metadata": {
        "id": "7EhRwF2uz0OW",
        "outputId": "e19d0eb8-526b-454f-b405-3f77406c1e32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le dossier GeneratedTextDetection-main a été supprimé avec succès.\n",
            "téléchargemet du dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": true,
        "id": "bQgqgPz3VsP6",
        "outputId": "8b898e8f-8b50-449f-cbed-17e0884e5b7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-25 15:55:23--  https://github.com/vijini/GeneratedTextDetection/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/vijini/GeneratedTextDetection/zip/refs/heads/main [following]\n",
            "--2025-02-25 15:55:23--  https://codeload.github.com/vijini/GeneratedTextDetection/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.116.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.116.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 819461 (800K) [application/zip]\n",
            "Saving to: ‘main.zip.1’\n",
            "\n",
            "main.zip.1          100%[===================>] 800.25K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-25 15:55:23 (19.0 MB/s) - ‘main.zip.1’ saved [819461/819461]\n",
            "\n",
            "Archive:  main.zip\n",
            "ab034465f857a93212a894fe598edb749345b6ff\n",
            "   creating: GeneratedTextDetection-main/\n",
            "  inflating: GeneratedTextDetection-main/BLEU_sentence.py  \n",
            "   creating: GeneratedTextDetection-main/Dataset/\n",
            "   creating: GeneratedTextDetection-main/Dataset/FullyGenerated/\n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.09779_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.09779_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10319_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10319_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10329_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10329_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10340_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10340_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10478_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10478_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10575_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10575_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10577_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10577_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10778_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10778_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10817_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.10817_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11115_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11115_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11205_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11205_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11207_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11207_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11589_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11589_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11879_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11879_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11984_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.11984_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12010_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12010_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12341_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12341_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12383_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12383_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12501_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12501_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12552_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12552_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12645_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12645_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12765_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.12765_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13229_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13229_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13317_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13317_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13472_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13472_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13658_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13658_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13900_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.13900_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.14532_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.14532_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15023_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15023_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15130_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15130_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15317_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15317_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15534_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15534_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15705_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15705_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15707_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15707_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15724_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15724_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15725_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15725_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15799_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15799_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15802_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2110.15802_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00035_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00035_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00086_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00086_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00180_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00180_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00310_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00310_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00514_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00514_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00526_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00526_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00554_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00554_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00572_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00572_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00607_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00607_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00667_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00667_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00808_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00808_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00867_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.00867_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01023_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01023_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01231_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01231_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01243_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01243_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01322_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01322_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01340_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01340_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01515_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01515_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01676_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01676_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01706_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.01706_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02041_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02041_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02110_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02110_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02188_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02188_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02259_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02259_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02326_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02326_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02362_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02362_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02574_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02574_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02643_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02643_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02687_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02687_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02760_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02760_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02844_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.02844_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03294_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03294_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03320_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03320_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03612_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03612_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03715_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03715_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03800_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03800_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03837_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03837_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03913_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03913_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03945_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.03945_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04130_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04130_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04416_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04416_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04507_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04507_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04574_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.04574_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05204_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05204_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05241_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05241_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05754_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.05754_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06012_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06012_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06181_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06181_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06230_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06230_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06464_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06464_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06580_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06580_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06644_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.06644_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07267_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07267_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07408_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07408_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07525_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07525_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07611_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07611_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07699_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07699_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07793_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.07793_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15093_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15093_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15436_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15436_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15473_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2111.15473_original.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2112.00405_generated.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/FullyGenerated/2112.00405_original.txt  \n",
            " extracting: GeneratedTextDetection-main/Dataset/FullyGenerated/data  \n",
            "   creating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/\n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09381_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09381_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09388_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09388_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09412_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09412_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09478_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09478_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09739_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09739_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09794_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09794_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09851_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09851_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09884_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09884_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09939_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.09939_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10044_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10044_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10056_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10056_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10280_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10280_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10291_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10291_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10297_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10297_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10309_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10309_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10452_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10452_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10476_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10476_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10488_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10488_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10501_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10501_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10518_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10518_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10522_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10522_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10545_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10545_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10595_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10595_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10622_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10622_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10625_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10625_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10627_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10627_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10734_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10734_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10772_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10772_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10831_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10831_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10832_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10832_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10847_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10847_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10896_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10896_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10897_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10897_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10898_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10898_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10970_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.10970_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11032_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11032_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11090_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11090_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11107_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11107_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11129_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11129_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11138_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11138_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11146_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11146_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11153_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11153_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11207_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11207_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11212_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11212_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11218_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11218_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11223_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11223_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11250_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11250_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11276_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11276_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11293_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11293_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11295_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11295_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11335_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11335_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11358_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11358_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11402_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11402_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11510_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11510_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11523_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11523_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11525_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11525_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11588_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11588_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11646_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11646_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11647_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11647_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11710_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11710_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11720_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11720_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11755_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11755_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11771_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11771_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11773_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11773_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11856_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11856_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11863_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11863_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11869_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11869_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11964_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11964_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11982_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.11982_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12024_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12024_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12055_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12055_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12144_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12144_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12170_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12170_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12197_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12197_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12202_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12202_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12210_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12210_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12454_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12454_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12490_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12490_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12498_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12498_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12560_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12560_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12602_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12602_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12606_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12606_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12679_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12679_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12906_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12906_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12978_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12978_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12986_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.12986_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13027_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13027_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13069_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13069_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13122_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13122_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13142_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13142_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13144_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13144_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13145_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13145_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13188_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13188_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13295_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13295_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13326_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13326_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13447_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13447_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13463_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13463_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13550_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13550_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13585_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13585_originalAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13654_generatedAbstract.txt  \n",
            "  inflating: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/2111.13654_originalAbstract.txt  \n",
            " extracting: GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset/data  \n",
            "  inflating: GeneratedTextDetection-main/README.md  \n",
            "  inflating: GeneratedTextDetection-main/n-gram_BLEU.py  \n",
            "  inflating: GeneratedTextDetection-main/rouge.py  \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/vijini/GeneratedTextDetection/archive/refs/heads/main.zip\n",
        "!unzip main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "N2CEFL-PVsP6"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UDIRAm1AVsP7"
      },
      "outputs": [],
      "source": [
        "root = Path(\"GeneratedTextDetection-main/Dataset/Hybrid_AbstractDataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "cRAWm2mrVsP7"
      },
      "outputs": [],
      "source": [
        "train_texts, train_labels, test_texts, test_labels = [], [], [], []\n",
        "for path in root.glob(\"*.txt\"):\n",
        "    with open(path, 'rt') as file:\n",
        "        text = file.read()\n",
        "        text = text.lstrip('\\ufeff')\n",
        "    label = int(path.name.endswith(\"generatedAbstract.txt\"))\n",
        "    doc_id = int(path.name.split(\"_\")[0].split(\".\")[-1])\n",
        "    if doc_id < 10522:\n",
        "        test_texts.append(text)\n",
        "        test_labels.append(label)\n",
        "    else:\n",
        "        train_texts.append(text)\n",
        "        train_labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4QVUO6vAVsP8",
        "outputId": "7a57a810-3d5a-4679-be36-93278697024d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 160, 40, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "len(train_texts), len(train_labels), len(test_texts), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QwMK9c6iVsP8",
        "outputId": "b2283c1c-7817-4f66-b556-cc5766329ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffMachine learning in medical imaging during clinical routine is impaired by changes in scan- ner protocols, hardware, or policies resulting in a heterogeneous set of acquisition settings. When training a deep learning model on an initial static training set, model performance and reliability suffer from changes of acquisition characteristics as data and targets may become inconsistent. Continual learning can help to adapt models to the changing environ- ment by training on a continuous data stream. However, continual manual expert labelling of medical imaging requires substantial effort. Thus, ways to use labelling resources ef- ficiently on a well chosen sub-set of new examples is necessary to render this strategy feasible. Here, we propose an integrated toolkit for automatic annotation of medical imaging , based on a deep embeddings framework for biomedical data, and present a method to automatically infer such annotation results using the full medical image corpus. The approach automatically recognizes shifts in image acquisition characteristics - new domains -, selects optimal examples for labelling and adapts training accordingly. Labelling is subject to a limited budget, resembling typ- ical real world scenarios. To demonstrate generalizability, we evaluate the effectiveness of our method on three tasks: cardiac segmentation, lung nodule detection and brain age estimation. Results show that the proposed approach outperforms other active learning methods, while effectively counteracting catastrophic forgetting.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "train_texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "luLbPRciVsP8",
        "outputId": "ecad1a30-29f0-4694-8dff-ed8bb76335f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "train_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wxv54Za-VsP9",
        "outputId": "36e23c81-435e-4714-f62b-2fa858e303a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffPublic policies that supply public goods, especially those involve collaboration by limiting individual liberty, always give rise to controversies over governance legitimacy. Multi-Agent Reinforcement Learning (MARL) methods are appropriate for supporting the legitimacy of the public policies that supply public goods at the cost of individual interests. Among these policies, the inter-regional collaborative pandemic control is a prominent example, which has become much more important for an increasingly inter-connected world facing a global pandemic like COVID-19. Different patterns of collaborative strategies have been observed among different systems of regions, yet it lacks an analytical process to reason for the legitimacy of those strategies. In this paper, we use the inter-regional collaboration for pandemic control as an example to demonstrate the necessity of MARL in reasoning, and thereby legitimizing policies enforcing such inter-regional collaboration. Exper- imental results in an exemplary environment show that our MARL approach is able to demonstrate the effectiveness and necessity of restrictions on individual liberty for collaborative supply of public goods. Different optimal policies are learned by our MARL agents under different collaboration levels, which change in an interpretable pattern of collaboration that helps to balance the losses suf- fered by regions of different types, and consequently promotes the overall welfare. Meanwhile, policies learned with higher collaboration levels yield higher global rewards, which illustrates the benefit of, and thus provides a novel justification for the legitimacy of, promoting inter-regional collaboration. Therefore, our method shows the capability of MARL in computationally modeling and supporting the theory of calculus of consent, developed by Nobel Prize winner J. M. Buchanan.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "train_texts[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "cJpoiYt5VsP9",
        "outputId": "d72b1c88-0f8c-42cc-beeb-0310cc03ce90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "train_labels[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlWApsrJVsP9"
      },
      "source": [
        "# Good luck!\n",
        "\n",
        "It's now up to you to solve the problem. You are free to choose any NLP method (cf. the list I gave above)\n",
        "but you should motivate your choice.\n",
        "You can also compare several methods to get bonus points. (compare 3 méthode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR3VXwlWVsP9"
      },
      "source": [
        "# Submission instructions\n",
        "\n",
        "\n",
        "**Deadline: Thursday 27th of February 23:59 (Paris CEST)** (strict deadline, 5 points malus per day late, so 4 days late means 0/20)\n",
        "\n",
        "This is a **group work** of **3 members**.\n",
        "\n",
        "You will have to submit your **code** and a **report** which will be graded (instructions below) by email to lerner@isir.upmc.fr.\n",
        "\n",
        "The homework (continuous assessment) will account for 50% of your final grade.\n",
        "\n",
        "## Report\n",
        "\n",
        "The report should be **a single .pdf file of max. 4 pages** (concision is key).\n",
        "Please name the pdf with the name of your group as written in the spreadsheet https://docs.google.com/spreadsheets/d/1UbApMhPC_wof-GoByjkV7kgD5YMbjcFFPqPUCB0YRtQ/edit?usp=sharing for example `ABC.pdf`.\n",
        "\n",
        "It should follow the following structure:\n",
        "\n",
        "### Introduction\n",
        "A few sentences placing the work in context. Limit it to a few paragraphs at most; since your report is based on Vijini et al., you don’t have to motivate that work. However, it should be clear enough what Vijini et al. is\n",
        "about and what its contributions are.\n",
        "\n",
        "### Methodology\n",
        "\n",
        "Describe the methods you are using to tackle the problem and motivate it: why this method and not another?  \n",
        "What are its advantages and inconvenients?  \n",
        "What experiment are you running to measure the efficiency or effectiveness of your method to tackle the problem?\n",
        "\n",
        "#### Model Descriptions\n",
        "Describe the models you used, including the architecture, learning objective and the number of parameters.\n",
        "\n",
        "#### Datasets\n",
        "Describe the datasets you used and how you obtained them.\n",
        "\n",
        "#### Hyperparameters\n",
        "Describe how you set the hyperparameters and what was the source for their value (e.g., paper, code, or your guess).\n",
        "\n",
        "#### Implementation\n",
        "Describe whether you use existing code or write your own code.\n",
        "\n",
        "#### Experimental Setup\n",
        "Explain how you ran your experiments, e.g. the CPU/GPU resources.\n",
        "\n",
        "### Results\n",
        "Start with a high-level overview of your results. Keep this\n",
        "section as factual and precise as possible.\n",
        "Logically\n",
        "group related results into sections.\n",
        "\n",
        "Remember to add plots and diagrams to illustrate your methods or results if necessary.\n",
        "\n",
        "\n",
        "\n",
        "### Discussion\n",
        "\n",
        "Describe which parts of your project were difficult or took much more time than you expected.\n",
        "\n",
        "\n",
        "### Contributions\n",
        "\n",
        "You should state the contributions of each member of the group.\n",
        "\n",
        "\n",
        "\n",
        "## Code\n",
        "\n",
        "You can submit your code either as:\n",
        "\n",
        "- single .zip file with your entire source code (e.g. several .py files)\n",
        "- link to a GitHub/GitLab repository (in this case, **include the link in your .pdf report**)\n",
        "- link to a Google Colab Notebook (your code may be quite simple so it may fit in a single notebook;\n",
        "  likewise, in this case, **include the link in your .pdf report**)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's start"
      ],
      "metadata": {
        "id": "gjgUSHD_y4cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#distribution"
      ],
      "metadata": {
        "id": "1PBFx2551Y3x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3B1kC9TB1b5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data wrangling"
      ],
      "metadata": {
        "id": "jDvJyKlWy9ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lstrip('\\ufeff')\n"
      ],
      "metadata": {
        "id": "1LnDzATpy8Lr"
      },
      "execution_count": 40,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}